{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6018ecf4-e5e5-4774-94fe-9862f85f7213",
   "metadata": {},
   "source": [
    "In this project, we have some pictures with some number of people. These pictures are evaluated by 2 different algorithm to count the people inside each picture. We should build a model to estimate the actual number of people, given the result of 2 algorithms and time in which each picture has taken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419bb8b8-19a3-48aa-95f1-73a2352dbec4",
   "metadata": {},
   "source": [
    "# Importing libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc63d5-0af5-4c53-a93d-4d4b776fc17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from xgboost import XGBRegressor\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a6565f-e956-4bb1-9b6a-cf8d86b7101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Relevant.txt')\n",
    "dataset.columns = ['first_algorithm', 'second_algoritm', 'day_time', 'people_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90720d5a-76c8-4530-93c5-a1da3d7a5358",
   "metadata": {},
   "source": [
    "# Data evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4f31a9-26a6-40f1-9e7b-4bf4d67b785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparison of each algorithms results with real data\n",
    "\n",
    "#Illustrate the difference of real data and first algorithm\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.subplot(2,1,1)\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.plot(dataset.index, dataset['first_algorithm'], label = 'First Algorithm', linewidth = 1)\n",
    "plt.plot(dataset.index, dataset['people_count'], label = 'Real Data', c='magenta', linewidth = 1)\n",
    "plt.ylabel('People Count')\n",
    "plt.legend(loc =(0.05,0.8))\n",
    "\n",
    "#Illustrate the difference of real data and second algorithm\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.subplot(2,1,2)\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.plot(dataset.index, dataset['second_algoritm'], label = 'Second Algorithm', c='red', linewidth = 1)\n",
    "plt.plot(dataset.index, dataset['people_count'], label = 'Real_Data', c='green', linewidth = 1)\n",
    "\n",
    "plt.ylabel('People Count')\n",
    "plt.legend(loc =(0.05,0.8))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb969cf0-10e0-4e91-b2a1-eeb20d772cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d54baca-c783-4e29-bf0a-0a95cd780ccf",
   "metadata": {},
   "source": [
    "We can conclude that both algorithms are counting more people than the truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acbe8b0-fdd3-457d-933e-c5013b3dce84",
   "metadata": {},
   "source": [
    "# Testing different regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd551c4-b7c3-42f0-aed5-c3b5327c73b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1]\n",
    "y = dataset.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfaad9d-8fd0-4fc8-953f-a35ff6fc15b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models_name = []\n",
    "LR = LinearRegression()\n",
    "KNN = KNeighborsRegressor(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "BRR = BayesianRidge()\n",
    "DT = DecisionTreeRegressor(random_state = 0)\n",
    "RF = RandomForestRegressor(n_estimators = 10, random_state = 1)\n",
    "XGB = XGBRegressor(n_estimators=500, max_depth = 5,gamma = 0, objective= 'reg:pseudohubererror')\n",
    "models.append(LR)\n",
    "models_name.append('Linear Regression')\n",
    "models.append(KNN)\n",
    "models_name.append('K Nearest Neighbor')\n",
    "models.append(BRR)\n",
    "models_name.append('Bayesian Ridge Regressor')\n",
    "models.append(DT)\n",
    "models_name.append('Decision Tree Regressor')\n",
    "models.append(RF)\n",
    "models_name.append('Random Forest Regressor')\n",
    "models.append(XGB)\n",
    "models_name.append('XGBoost Regressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2438068-2590-4f82-bce6-62502b563d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "scores = []\n",
    "for i in range(len(models)):\n",
    "    score = cross_val_score(models[i], X, y, cv= kfold)\n",
    "    scores.append(score)\n",
    "    print(models_name[i],':', round(score.mean(),3),',', round(score.std(),3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25c016e-09e4-43b5-befb-b97c98fec540",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.boxplot(scores, labels = models_name)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e861f5b-8488-434b-a6b0-2f1392477209",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = {}\n",
    "y_pred_test = {}\n",
    "for i in range(len(models)):\n",
    "    models[i].fit(X_train, y_train)\n",
    "    print(models_name[i])\n",
    "    print('Train Set Score', models[i].score(X_train, y_train))\n",
    "    print('Test Set Score', models[i].score(X_test, y_test))\n",
    "    y_pred[models_name[i]] = models[i].predict(X)\n",
    "    y_pred_test[models_name[i]] = models[i].predict(X_test)\n",
    "    print('MSE', mean_squared_error(y_test, y_pred_test[models_name[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edfe091-7e42-40dd-ba50-2694e4343759",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 25))\n",
    "plt.subplot(611)\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.scatter(dataset.index, dataset['people_count'], label = 'Real_Data', c='green', s = 12)\n",
    "plt.plot(dataset.index, y_pred['Linear Regression'], label = 'Linear Regression', c='red', linewidth = 1)\n",
    "plt.ylabel('People Count')\n",
    "plt.title('Regression Models Prediction')\n",
    "plt.legend(loc =(0.05,0.8))\n",
    "\n",
    "plt.figure(figsize=(20, 25))\n",
    "plt.subplot(612)\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.scatter(dataset.index, dataset['people_count'], label = 'Real_Data', c='green', s = 12)\n",
    "plt.plot(dataset.index, y_pred['Bayesian Ridge Regressor'], label = 'Bayesian Ridge Regressor', c='red', linewidth = 1)\n",
    "plt.ylabel('People Count')\n",
    "plt.legend(loc =(0.05,0.8))\n",
    "\n",
    "plt.figure(figsize=(20, 25))\n",
    "plt.subplot(613)\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.scatter(dataset.index, dataset['people_count'], label = 'Real_Data', c='green', s = 12)\n",
    "plt.plot(dataset.index, y_pred['Decision Tree Regressor'], label = 'Decision Tree Regressor', c='red', linewidth = 1)\n",
    "plt.ylabel('People Count')\n",
    "plt.legend(loc =(0.05,0.8))\n",
    "\n",
    "plt.figure(figsize=(20, 25))\n",
    "plt.subplot(614)\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.scatter(dataset.index, dataset['people_count'], label = 'Real_Data', c='green', s = 12)\n",
    "plt.plot(dataset.index, y_pred['Random Forest Regressor'], label = 'Random Forest Regressor', c='red', linewidth = 1)\n",
    "plt.ylabel('People Count')\n",
    "plt.legend(loc =(0.05,0.8))\n",
    "\n",
    "plt.figure(figsize=(20, 25))\n",
    "plt.subplot(615)\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.scatter(dataset.index, dataset['people_count'], label = 'Real_Data', c='green', s = 12)\n",
    "plt.plot(dataset.index, y_pred['K Nearest Neighbor'], label = 'K Nearest Neighbor', c='red', linewidth = 1)\n",
    "plt.ylabel('People Count')\n",
    "plt.legend(loc =(0.05,0.8))\n",
    "\n",
    "plt.figure(figsize=(20, 25))\n",
    "plt.subplot(615)\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.scatter(dataset.index, dataset['people_count'], label = 'Real_Data', c='green', s = 12)\n",
    "plt.plot(dataset.index, y_pred['XGBoost Regressor'], label = 'XGBoost Regressor', c='red', linewidth = 1)\n",
    "plt.ylabel('People Count')\n",
    "plt.legend(loc =(0.05,0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d733bbf3-3424-48bd-946f-2f402a3fd00c",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning of 2 algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7411a5cb-1117-4720-aa23-b4a503ec9644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f9d943-d53b-4b0d-ad4c-9713b9525169",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BRR\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b0d9c-eafe-4775-bbc3-8cc5293b5b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BRR_objective(BRR_trial):\n",
    "    alpha1 = BRR_trial.suggest_float('alpha_1', 1e-06, 1000)\n",
    "    lambda1 = BRR_trial.suggest_float('lambda_1', 1e-06, 1000)\n",
    "    alpha2 = BRR_trial.suggest_float('alpha_2', 1e-06, 1000)\n",
    "    lambda2 = BRR_trial.suggest_float('lambda_2', 1e-06, 1000)\n",
    "    iter_count = BRR_trial.suggest_int('n_iter', 300, 1000)\n",
    "    model = BayesianRidge(alpha_1= alpha1, lambda_1= lambda1, alpha_2= alpha2, lambda_2= lambda2, n_iter= iter_count)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return(model.score(X_test, y_test))\n",
    "\n",
    "\n",
    "BRR_study = optuna.create_study(direction='maximize')\n",
    "BRR_study.optimize(BRR_objective, n_trials= 100, n_jobs=-1)\n",
    "BRR_trial = BRR_study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(BRR_trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(BRR_trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee44770-745d-437f-95cc-5d4428a4c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BayesianRidge(alpha_1= BRR_trial.params['alpha_1'],\n",
    "                      alpha_2= BRR_trial.params['alpha_2'],\n",
    "                      lambda_1= BRR_trial.params['lambda_1'],\n",
    "                      lambda_2= BRR_trial.params['lambda_2'],\n",
    "                      n_iter= BRR_trial.params['n_iter'])\n",
    "model.fit(X_train, y_train)\n",
    "print('Train Set Score', round(model.score(X_train, y_train), 4))\n",
    "print('Test Set Score', round(model.score(X_test, y_test), 4))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "print('MSE', round(mean_squared_error(y_test, Y_pred),4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2ba721-405d-46da-a129-419c1d5c3d2d",
   "metadata": {},
   "source": [
    "Due to slight change of the BRR model, I decide to tune hyperparameters of XGB model, with the hope of getting a better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058c8d13-3e55-46fa-8500-8511883897e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGB\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7494d313-94f7-451f-856a-8ce3fd2631aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_objective(XGB_trial):\n",
    "    max_depth = XGB_trial.suggest_int('max_depth', 2,20)\n",
    "    min_child_weight = XGB_trial.suggest_int('min_child_weight', 1, 100)\n",
    "    reg_alpha = XGB_trial.suggest_float('reg_alpha', 0, 10)\n",
    "    reg_lambda = XGB_trial.suggest_float('reg_lambda', 1, 10)\n",
    "    n_estimator = XGB_trial.suggest_int('n_estimator', 20, 1000)\n",
    "    model = XGBRegressor(max_depth= max_depth, min_child_weight= min_child_weight,\n",
    "                         reg_alpha= reg_alpha, reg_lambda= reg_lambda,\n",
    "                         n_estimators= n_estimator, objective= 'reg:pseudohubererror')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred= model.predict(X_test)\n",
    "    y_pred[y_pred>50] = 50\n",
    "    return(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "XGB_study = optuna.create_study(direction='minimize')\n",
    "XGB_study.optimize(XGB_objective, n_trials= 100, n_jobs=-1)\n",
    "XGB_trial = XGB_study.best_trial\n",
    "\n",
    "print('MSE: {}'.format(XGB_trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(XGB_trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c4bae9-bb3c-47cf-926a-20c22171e6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(max_depth= XGB_trial.params['max_depth'],\n",
    "                    min_child_weight= XGB_trial.params['min_child_weight'],\n",
    "                    reg_alpha= XGB_trial.params['reg_alpha'],\n",
    "                    reg_lambda= XGB_trial.params['reg_lambda'],\n",
    "                    n_estimators= XGB_trial.params['n_estimator'],\n",
    "                    objective= 'reg:pseudohubererror')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print('Train Set Score', round(model.score(X_train, y_train), 4))\n",
    "print('Test Set Score', round(model.score(X_test, y_test), 4))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "print('MSE', round(mean_squared_error(y_test, Y_pred),4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
